#!/usr/bin/env python3
“””
BMAC3 Flight Tracker - Parser & Uploader
Reads raw XML file, parses flight data, uploads to Azure SQL.
Deletes processed data from the XML file to save disk space.
Controlled via bmac3_state.json (start/stop from Home Assistant)
“””
import re
import sys
import os
import json
import time
import logging
import xml.etree.ElementTree as ET

sys.path.insert(0, os.path.dirname(os.path.abspath(**file**)))
from config import *

try:
import pyodbc
except ImportError:
print(“pyodbc not installed. Run: pip install pyodbc –break-system-packages”)
sys.exit(1)

logging.basicConfig(
filename=LOG_FILE,
level=logging.INFO,
format=”%(asctime)s [PARSER] %(message)s”
)

def get_state():
try:
with open(HA_STATE_FILE, “r”) as f:
return json.load(f)
except:
return {“collector_enabled”: True}

def save_state(state):
with open(HA_STATE_FILE, “w”) as f:
json.dump(state, f, indent=2)

def connect_azure():
“”“Connect to Azure SQL”””
try:
conn = pyodbc.connect(AZURE_CONN_STR)
logging.info(“Connected to Azure SQL”)
return conn
except Exception as e:
logging.error(f”Azure connection failed: {e}”)
return None

def parse_flight(xml_string):
“””
Parse a single <message> block and extract flight data.

```
THIS IS THE PARSING LOGIC - edit this function to adjust 
how flight data is extracted from the XML.
"""
try:
    # Wrap message in root element with namespaces
    wrapped = (
        '<?xml version="1.0" encoding="UTF-8"?>'
        '<ns5:MessageCollection xmlns:ns5="http://www.faa.aero/nas/3.0" '
        'xmlns:ns2="http://www.fixm.aero/base/3.0" '
        'xmlns:ns3="http://www.fixm.aero/flight/3.0" '
        'xmlns:ns4="http://www.fixm.aero/foundation/3.0" '
        'xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">'
        + xml_string +
        '</ns5:MessageCollection>'
    )

    root = ET.fromstring(wrapped)
    flight = root.find('.//ns5:flight', NS)
    if flight is None:
        return None

    data = {}

    # ── Timestamp & Center ──
    data['timestamp'] = flight.get('timestamp')
    data['center'] = flight.get('centre')

    # ── Callsign (attribute on flightIdentification) ──
    flight_id = flight.find('.//ns5:flightIdentification', NS)
    if flight_id is not None:
        data['callsign'] = flight_id.get('aircraftIdentification')
        data['computer_id'] = flight_id.get('computerId')

    # ── Departure ──
    departure = flight.find('.//ns5:departure', NS)
    if departure is not None:
        data['departure'] = departure.get('departurePoint')

    # ── Arrival ──
    arrival = flight.find('.//ns5:arrival', NS)
    if arrival is not None:
        data['arrival'] = arrival.get('arrivalPoint')

    # ── Flight Status ──
    status = flight.find('.//ns5:flightStatus', NS)
    if status is not None:
        data['status'] = status.get('fdpsFlightStatus')

    # ── Operator ──
    org = flight.find('.//ns5:operator/ns5:operatingOrganization/ns5:organization', NS)
    if org is not None:
        data['operator'] = org.get('name')

    # ── GUFI ──
    gufi = flight.find('.//ns5:gufi', NS)
    if gufi is not None:
        data['gufi'] = gufi.text

    # ── Position (lat/long) ──
    pos = flight.find('.//ns2:pos', NS)
    if pos is not None and pos.text:
        coords = pos.text.strip().split()
        if len(coords) == 2:
            data['latitude'] = float(coords[0])
            data['longitude'] = float(coords[1])

    # ── Altitude ──
    altitude = flight.find('.//ns2:altitude', NS)
    if altitude is not None and altitude.text:
        data['altitude'] = int(float(altitude.text))

    # ── Speed ──
    speed = flight.find('.//ns2:speed', NS)
    if speed is not None and speed.text:
        data['speed'] = int(float(speed.text))

    # ── Heading ──
    heading = flight.find('.//ns2:heading', NS)
    if heading is not None and heading.text:
        data['heading'] = int(float(heading.text))

    return data if data.get('callsign') else None

except Exception as e:
    logging.error(f"Parse error: {e}")
    return None
```

def upload_batch(conn, flights):
“”“Upload a batch of parsed flights to Azure SQL”””
if not flights:
return 0

```
cursor = conn.cursor()
count = 0

try:
    for f in flights:
        cursor.execute('''
            INSERT INTO flights 
            (timestamp, callsign, aircraft_type, registration, departure, arrival,
             latitude, longitude, altitude, speed, heading, status, operator, center, gufi)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            f.get('timestamp'),
            f.get('callsign'),
            f.get('aircraft_type'),
            f.get('registration'),
            f.get('departure'),
            f.get('arrival'),
            f.get('latitude'),
            f.get('longitude'),
            f.get('altitude'),
            f.get('speed'),
            f.get('heading'),
            f.get('status'),
            f.get('operator'),
            f.get('center'),
            f.get('gufi'),
        ))
        count += 1

    conn.commit()
    logging.info(f"Uploaded {count} flights to Azure")
    return count

except Exception as e:
    logging.error(f"Upload error: {e}")
    conn.rollback()
    return 0
```

def process_file(conn):
“””
Read raw XML file, extract messages, parse and upload.
Then truncate the file to free disk space.
“””
if not os.path.exists(RAW_XML_FILE):
return 0

```
# Read current file
with open(RAW_XML_FILE, "r") as f:
    content = f.read()

if not content.strip():
    return 0

# Find all complete <message>...</message> blocks
pattern = r'(<message\s[^>]*>.*?</message>)'
messages = re.findall(pattern, content, re.DOTALL)

if not messages:
    return 0

logging.info(f"Found {len(messages)} messages to process")

# Parse all messages
flights = []
for msg in messages:
    flight = parse_flight(msg)
    if flight:
        flights.append(flight)

logging.info(f"Parsed {len(flights)} valid flights")

# Upload to Azure
uploaded = upload_batch(conn, flights)

if uploaded > 0:
    # Remove processed messages from file (keep anything after last </message>)
    last_msg_end = content.rfind('</message>') + len('</message>')
    remaining = content[last_msg_end:]

    with open(RAW_XML_FILE, "w") as f:
        f.write(remaining)

    logging.info(f"Trimmed processed data from {RAW_XML_FILE}")

return uploaded
```

def main():
logging.info(“Parser starting…”)

```
while True:
    state = get_state()

    if not state.get("collector_enabled", True):
        time.sleep(PARSE_INTERVAL_SECONDS)
        continue

    # Connect to Azure
    conn = connect_azure()
    if not conn:
        state = get_state()
        state["error"] = "Failed to connect to Azure SQL"
        state["parser_running"] = False
        save_state(state)
        time.sleep(30)
        continue

    state = get_state()
    state["parser_running"] = True
    state["error"] = None
    save_state(state)

    try:
        while True:
            state = get_state()
            if not state.get("collector_enabled", True):
                break

            uploaded = process_file(conn)

            if uploaded > 0:
                state = get_state()
                state["total_rows_uploaded"] = state.get("total_rows_uploaded", 0) + uploaded
                state["last_upload_count"] = uploaded
                state["last_upload_time"] = time.strftime("%Y-%m-%d %H:%M:%S")
                save_state(state)

            time.sleep(PARSE_INTERVAL_SECONDS)

    except Exception as e:
        logging.error(f"Parser error: {e}")
        state = get_state()
        state["error"] = str(e)
        state["parser_running"] = False
        save_state(state)
    finally:
        if conn:
            conn.close()
        time.sleep(10)
```

if **name** == “**main**”:
main()
